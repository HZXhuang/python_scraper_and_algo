import os
from scraper import base_path
from scraper.my_utils import identify_lang
import emoji
import pandas as pd
from sql_dao.sql_utils import db_engine, text


def save_file():
    print(base_path)
    # with open("/static/my.txt", "w", encoding="utf-8") as f:
    #     f.write("ä½ å¥½")


def lang_detect():
    conn = db_engine.connect()
    query_sql = "select * from raw_comment"
    update_sql = "update raw_comment set language = '{}' where id = {}"
    df = pd.read_sql(query_sql, conn)
    for i in range(len(df)):
        ID = df.iloc[i]["id"]
        content = df.iloc[i]["content"]
        lang = identify_lang(content)
        conn.execute(text(update_sql.format(lang, ID)))
    conn.commit()
    conn.close()


if __name__ == "__main__":
    # save_file()
    # print(os.listdir(base_path))
    # print(datetime.datetime.now() - pd.Timedelta(weeks=2))
    # text = "è§£è¯´å¾ˆå¥½ï¼Œå°±æ˜¯å¹¿å‘Šå¤ªå¤šäº†ğŸ˜¢å¾ˆä¸é”™â¤â¤â¤ğŸŒ¹ğŸŒ¹ğŸŒ¹ğŸ‘ ğŸ˜‚ ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­â¤ğŸ‰ğŸ˜‚ğŸ‰ğŸ‰â¤â¤ğŸ¤£â¤ï¸ğŸ«°"
    # print(emoji.replace_emoji(text, ""))
    # df = pd.read_csv("./out/æµæµªåœ°çƒ2_Youtube.csv", sep="|", encoding="utf-8")
    # print(df)
    lang_detect()
    pass
