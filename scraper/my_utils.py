import langid
import random
from scraper import base_path, max_comment_len
from scraper import code_country_map
import os
import re
from snownlp import SnowNLP
import pandas as pd
from pypinyin import lazy_pinyin
from datetime import datetime
import emoji


# è¯†åˆ«å¥å­çš„è¯­è¨€ï¼Œå¹¶è¿”å›æ‰€å±å›½å®¶
def identify_lang_to_country(sentence):
    la_id = langid.classify(sentence)
    # print(la_id)
    try:
        country = code_country_map[la_id[0]]
        # print(type(country))
        if type(country) == list:
            idx = random.randint(0, len(country) - 1)
            return country[idx]
        else:
            return country
    except KeyError as e:
        print(e)
        return "æœªçŸ¥å›½å®¶"


def fan_to_jian(sentence):
    if len(sentence.strip()) == 0:
        return "ç©ºæ–‡æœ¬"
    s = SnowNLP(sentence)
    return s.han


def check_exists_and_make_dir(dir_name):
    dir_path = base_path + "/{}".format(dir_name)
    if dir_name not in os.listdir(base_path):
        os.mkdir(dir_path)


# å¯¹æ–‡æœ¬è¿›è¡Œæ¸…æ´—ï¼Œå»é™¤htmlæ ‡ç­¾ï¼Œå°†ä¸€äº›ç‰¹æ®Šå­—ç¬¦è¿›è¡Œè½¬æ¢
def text_clean(text):
    pattern = re.compile(r'<[^>]+>', re.S)
    result = pattern.sub("", text).replace("&quot;", "").replace("&#39;", "'").replace("\"", "")
    result = emoji.replace_emoji(result, "").replace("\n", "").replace("|", "")  # æ¸…é™¤è¡¨æƒ…åŒ…
    # print(result)
    if len(result) >= max_comment_len:
        result = result[:max_comment_len - 1]
    return result


# åˆ†ææ–‡æœ¬æ‰€åŒ…å«çš„æƒ…æ„Ÿææ€§ï¼Œç§¯ææˆ–æ¶ˆæ
def analyze_polarity(text):
    if len(text) == 0:
        return "ä¸­ç«‹"
    res = SnowNLP(text)
    # print(res.sentiments)
    if res.sentiments <= 0.4:
        return "æ¶ˆæ"
    elif res.sentiments <= 0.6:
        return "ä¸­ç«‹"
    else:
        return "ç§¯æ"


# åˆ†æå•è¯çš„è¯æ€§ï¼Œæ­£é¢ã€ä¸­æ€§ã€è´Ÿé¢
def analyze_word_polarity(text):
    if len(text) == 0:
        return "ä¸­æ€§"
    res = SnowNLP(text)
    # print(res.sentiments)
    if res.sentiments <= 0.4:
        return "è´Ÿé¢"
    elif res.sentiments <= 0.6:
        return "ä¸­æ€§"
    else:
        return "æ­£é¢"


# è§£æå­—ç¬¦ä¸²æ—¶é—´ï¼Œè¿”å›æ ‡å‡†æ ¼å¼çš„æ—¥æœŸ
def parse_date_format(time_text):
    if "å¹´" in time_text:
        return time_text.replace("å¹´", "-").replace("æœˆ", "-").replace("æ—¥", "")
    else:
        res = pd.to_datetime(time_text)
        return str(res.date())


# é€šè¿‡è·ç¦»å½“å‰æ—¶é—´é•¿åº¦è®¡ç®—æ—¥æœŸ
def parse_relative_date(time_text: str):
    if "å¹´" in time_text:
        formatted = datetime.now() - pd.Timedelta(days=int(time_text.replace("å¹´", ""))*365)
    elif "æœˆ" in time_text:
        formatted = datetime.now() - pd.Timedelta(days=int(time_text.replace("æœˆ", ""))*30)
    elif "å‘¨" in time_text:
        formatted = datetime.now() - pd.Timedelta(weeks=int(time_text.replace("å‘¨", "")))
    elif "å¤©" in time_text:
        formatted = datetime.now() - pd.Timedelta(days=int(time_text.replace("å¤©", "")))
    elif "å°æ—¶" in time_text:
        formatted = datetime.now() - pd.Timedelta(hours=int(time_text.replace("å°æ—¶", "")))
    elif "åˆ†é’Ÿ" in time_text:
        formatted = datetime.now() - pd.Timedelta(minutes=int(time_text.replace("åˆ†é’Ÿ", "")))
    else:
        formatted = datetime.now()
    return formatted.date()


# è§£ææ•°å­— æ’­æ”¾æ¬¡æ•°
def parse_num(text: str):
    if "ä¸‡" in text:
        return float(text.replace("ä¸‡", "").replace(" ", "").replace(",", ""))*10000
    else:
        return float(text.replace(",", "").replace(" ", ""))


# å°†ä¸­æ–‡è½¬æ¢æˆæ‹¼éŸ³
def chinese_to_pinyin(sentence):
    res = lazy_pinyin(sentence)
    return " ".join(res)


if __name__ == "__main__":
    # print(identify_lang_to_country("é¥¥é¥¿è¥é”€ã€‚ã€‚"))
    # res = text_clean('æ„Ÿæ©å¤§è°çš„è§£èªªâ¤ï¸ğŸ«°')
    # print(res)
    # text = "Who am I to write a review of a collection of 600 year old Chinese fairytales? This edition, with notes about the translation and a great introduction, and with its updated language, is accessible, fun, and despite what Goodreads thinks, I read this over the course of a week or so, in enjoyable chunks, probably more like what was intended. I recommend this to anyone who'd like a grounding in Chinese myth or culture that they don't already have."[:150]
    # print(text)
    # print(analyze_polarity("ä¸€èˆ¬"))
    # print(parse_date_format("2023-07-18T04:59:05.000Z"))
    # print(chinese_to_pinyin("æµæµªåœ°çƒ"))
    # print(parse_relative_date("4å¤©"))
    print(fan_to_jian("EN ESPAÃ‘OL porfavor o en ingles"))
    pass